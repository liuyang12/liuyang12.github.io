[{"authors":["admin"],"categories":null,"content":"Yang Liu is a fifth-year PhD student working on computational imaging/photography with Prof. Frédo Durand at MIT EECS \u0026amp; CSAIL. He is excited about seeing, making, and connecting (almost) anything. He emphasizes on imaging and sensing beyond human vision (in terms of dimensionality and visibility) by combining optical imaging systems with compressive sensing and machine learning techniques. Typical topics that he is currently enthusiastic about are high-dimensional visual computing from low-dimensional samplings, such as high-throughput imaging, and single-pixel imaging, and non-line-of-sight imaging. Prior to this, he received his bachelor’s and master’s degrees from Tsinghua University in 2016 and 2019, respectively. He worked on computational imaging and microscopy, advised by Prof. Qionghai Dai and working closely with Prof. Jinli Suo.\nHe is broadly interested in artificial intelligence for accelerating scientific discovery and meeting social needs. He also worked on revealing the imaging threat of ambient light sensors on everyday screens, which is capable of resolving an image of the scene in front of the screen without accessing the selfie camera, and designing a privacy-preserving intradermal barcode and a robust recognition system as vaccine record and beyond (general on-patient medical record). [Spotlight by MIT CSAIL]\nNews [check out my notion site for latest updates and google scholar for papers] Organizing graphics side of MIT Vision and Graphics Seminar. Shoot me an email if you are interested! 2022\u0026ndash;2023 Taking MAS.863 How-to-Make class making my own content creation for fun! 2022 Fall Received Takeda Fellowship (2022-2023) from MIT-Takeda Program. Thanks Takeda! 2022.06 Research Spotlight by MIT CSAIL. Thanks Matt and Nate for neat production! 2022.04 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Yang Liu is a fifth-year PhD student working on computational imaging/photography with Prof. Frédo Durand at MIT EECS \u0026amp; CSAIL. He is excited about seeing, making, and connecting (almost) anything. He emphasizes on imaging and sensing beyond human vision (in terms of dimensionality and visibility) by combining optical imaging systems with compressive sensing and machine learning techniques. Typical topics that he is currently enthusiastic about are high-dimensional visual computing from low-dimensional samplings, such as high-throughput imaging, and single-pixel imaging, and non-line-of-sight imaging.","tags":null,"title":"Yang Liu","type":"authors"},{"authors":["yliu"],"categories":null,"content":"Yang Liu is a fifth-year PhD student working on generative image synthesis and computational imaging/photography with Prof. Frédo Durand at MIT EECS \u0026amp; CSAIL. He is excited about seeing, making, and connecting (almost) anything. He emphasizes on structured diffusion image synthesis, imaging and sensing beyond human vision (in terms of dimensionality and visibility) by combining optical imaging systems with compressive sensing and machine learning techniques.\nPrior to this, he received his bachelor’s and master’s degrees from Tsinghua University in 2016 and 2019, respectively. He worked on computational imaging and microscopy, advised by Prof. Qionghai Dai and working closely with Prof. Jinli Suo.\nHe is broadly interested in artificial intelligence for accelerating scientific discovery and meeting social needs. He also worked on revealing the imaging threat of ambient light sensors on everyday screens, which is capable of resolving an image of the scene in front of the screen without accessing the selfie camera, and designing a privacy-preserving intradermal barcode and a robust recognition system as vaccine record and beyond (general on-patient medical record). [Spotlight by MIT CSAIL]\nNews [check out my notion site for latest updates and google scholar for papers] Paper Privacy Dual Imaging has been accepted by Science Advances! 2023.12 Co-Organizing MIT Graphics Seminars (weekly lunch format) with Karima. Shoot us an email if you are interested! 2023\u0026ndash;2024 Taking MAS.863 How-to-Make class making my own content creation for fun! 2022 Fall Received Takeda Fellowship (2022-2023) from MIT-Takeda Program. Thanks Takeda! 2022.06 Research Spotlight by MIT CSAIL. Thanks Matt and Nate for neat production! 2022.04 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9fd98f55b5411d485e0eaf9c1a536255","permalink":"/authors/yliu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yliu/","section":"authors","summary":"Yang Liu is a fifth-year PhD student working on generative image synthesis and computational imaging/photography with Prof. Frédo Durand at MIT EECS \u0026amp; CSAIL. He is excited about seeing, making, and connecting (almost) anything. He emphasizes on structured diffusion image synthesis, imaging and sensing beyond human vision (in terms of dimensionality and visibility) by combining optical imaging systems with compressive sensing and machine learning techniques.\nPrior to this, he received his bachelor’s and master’s degrees from Tsinghua University in 2016 and 2019, respectively.","tags":null,"title":"Yang Liu","type":"authors"},{"authors":["[__Yang Liu__](https://yangliu.mit.edu/)✉","[Gregory W. Wornell](http://allegro.mit.edu/~gww/)","[William T. Freeman](https://billf.mit.edu/)","[Frédo Durand](http://people.csail.mit.edu/fredo/)✉"],"categories":null,"content":"Video Initial Poster video at ICCP 2021.\nHighlight Research Spotlight by MIT CSAIL in April 2022. Thanks Matt and Nate for neat production!\nAcknowledgement This work was supported in part by the DARPA REVEAL program (HR0011-16-C-0030) and MIT Stata Family Presidential Fellowship (Y.L.). We thank L. Murmann, P. Sharma, A. Yedidia, V. K. Goyal, J. H. Shapiro, F. N. C. Wong, C. Saunders, S. P. Bangaru, T.-M. Li, X. Yuan, J. Suo, A. Kaspar, R. Spreitzer, F. Asim for discussions, and L. Anderson, T. Rubio for proofreading.\nbibtex @article{Liu23PDI, author = {Liu, Yang and Wornell, Gregory W. and Freeman, William T. and Durand, Fr{\\\u0026#39;e}do}, title = {Imaging Privacy Threats from an Ambient Light Sensor}, journal = {Science Advances}, year = {2023}, doi = {10.1126/sciadv.adj3608}, type = {Journal Article} } ","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701388800,"objectID":"4c264063b2edabcd21d31dff7e1ad830","permalink":"/proj/privacy_dual_imaging/","publishdate":"2023-12-01T00:00:00Z","relpermalink":"/proj/privacy_dual_imaging/","section":"proj","summary":"Embedded sensors in smart devices pose privacy risks, often unintentionally leaking user information. We investigate how combining an ambient light sensor with a device display can capture an image of touch interaction without a camera. By displaying a known video sequence, we use the light sensor to capture reflected light intensity variations partially blocked by the touching hand, formulating an inverse problem similar to single-pixel imaging. Due to sensors' heavy quantization and low sensitivity, we propose an inversion algorithm involving an $\\ell_p$-norm dequantizer and a deep denoiser as natural image priors, to reconstruct images from the screen’s perspective. We demonstrate touch interactions and eavesdropping hand gestures on an off-the-shelf Android tablet. Despite limitations in resolution and speed, we aim to raise awareness of potential security/privacy threats induced by the combination of passive and active components in smart devices, and promote the development of ways to mitigate them.","tags":null,"title":"Imaging Privacy Threats from an Ambient Light Sensor","type":"proj"},{"authors":["[Xin Yuan](https://scholar.google.com/citations?user=cS9CbWkAAAAJ)†","[__Yang Liu__](https://yangliu.mit.edu/)†","[Jinli Suo](https://sites.google.com/site/suojinli)","[Frédo Durand](http://people.csail.mit.edu/fredo/)","[Qionghai Dai](http://media.au.tsinghua.edu.cn)"],"categories":null,"content":"bibtex @article{Yuan21PnPvideo, author = {Yuan, Xin and Liu, Yang and Suo, Jinli and Durand, Fr{\\\u0026#39;e}do and Dai, Qionghai}, title = {Plug-and-Play Algorithms for Video Snapshot Compressive Imaging}, journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence}, doi = {10.1109/TPAMI.2021.3099035}, year = {2022}, month = {10}, volume = {44}, number = {10}, pages = {7093 -- 7111}, url = {https://doi.org/10.1109/TPAMI.2021.3099035}, publisher = {IEEE}, type = {Journal Article} } ","date":1664582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664582400,"objectID":"352d13455f4715ce48da2dd3ab1662fd","permalink":"/proj/sci_pnp_video/","publishdate":"2022-10-01T00:00:00Z","relpermalink":"/proj/sci_pnp_video/","section":"proj","summary":"We consider the reconstruction problem of video snapshot compressive imaging (SCI), which captures high-speed videos using a low-speed 2D sensor (detector). The underlying principle of SCI is to modulate sequential high-speed frames with different masks and then these encoded frames are integrated into a snapshot on the sensor and thus the sensor can be of low-speed. On one hand, video SCI enjoys the advantages of low-bandwidth, low-power and low-cost. On the other hand, applying SCI to large-scale problems (HD or UHD videos) in our daily life is still challenging and one of the bottlenecks lies in the reconstruction algorithm. Existing algorithms are either too slow (iterative optimization algorithms) or not flexible to the encoding process (deep learning based end-to-end networks). In this paper, we develop fast and flexible algorithms for SCI based on the plug-and-play (PnP) framework. In addition to the PnP-ADMM method, we further propose the PnP-GAP (generalized alternating projection) algorithm with a lower computational workload. We first employ the image deep denoising priors to show that PnP can recover a UHD color video with 30 frames from a snapshot measurement. Since videos have strong temporal correlation, by employing the video deep denoising priors, we achieve a significant improvement in the results. Furthermore, we extend the proposed PnP algorithms to the color SCI system using mosaic sensors, where each pixel only captures the red, green or blue channels. A joint reconstruction and demosaicing paradigm is developed for flexible and high quality reconstruction of color video SCI systems. Extensive results on both simulation and real datasets verify the superiority of our proposed algorithm.","tags":null,"title":"Plug-and-Play Algorithms for Video Snapshot Compressive Imaging","type":"proj"},{"authors":["[Zhihong Zhang](https://github.com/zhihongz)†","[Chao Deng](https://scholar.google.com/citations?user=GkAO16kAAAAJ)†","[__Yang Liu__](https://yangliu.mit.edu/)","[Xin Yuan](https://scholar.google.com/citations?user=cS9CbWkAAAAJ)","[Jinli Suo](https://sites.google.com/site/suojinli)✉","[Qionghai Dai](http://media.au.tsinghua.edu.cn)"],"categories":null,"content":"bibtex @article{Li21SPY, author = {Zhang, Zhihong and Deng, Chao and Liu, Yang and Yuan, Xin and Suo, Jinli and Dai, Qionghai}, title = {Ten-mega-pixel snapshot compressive imaging with a hybrid coded aperture}, journal = {Photonics Research}, doi = {10.1364/PRJ.435256}, year = {2021}, month = {11}, volume = {9}, number = {11}, pages = {2277--2287}, url = {https://doi.org/10.1364/PRJ.435256}, publisher = {Optica Publishing Group}, type = {Journal Article} } ","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"a0e78a60df7c323c150b2b7fd1287e90","permalink":"/proj/sci_hybrid/","publishdate":"2021-11-01T00:00:00Z","relpermalink":"/proj/sci_hybrid/","section":"proj","summary":"High-resolution images are widely used in our everyday life; however, high-speed video capture is more challenging due to the low frame rate of cameras working at the high-resolution mode. The main bottleneck lies in the low throughput of existing imaging systems. Toward this end, snapshot compressive imaging (SCI) was proposed as a promising solution to improve the throughput of imaging systems by compressive sampling and computational reconstruction. During acquisition, multiple high-speed images are encoded and collapsed to a single measurement. Then, algorithms are employed to retrieve the video frames from the coded snapshot. Recently developed plug-and-play algorithms made the SCI reconstruction possible in large-scale problems. However, the lack of high-resolution encoding systems still precludes SCI’s wide application. Thus, in this paper, we build, to the best of our knowledge, a novel hybrid coded aperture snapshot compressive imaging (HCA-SCI) system by incorporating a dynamic liquid crystal on silicon and a high-resolution lithography mask. We further implement a PnP reconstruction algorithm with cascaded denoisers for high-quality reconstruction. Based on the proposed HCA-SCI system and algorithm, we obtain a 10-mega-pixel SCI system to capture high-speed scenes, leading to a high throughput of 4.6×109 voxels per second. Both simulation and real-data experiments verify the feasibility and performance of our proposed HCA-SCI scheme.","tags":null,"title":"Ten-Mega-Pixel Snapshot Compressive Imaging with a Hybrid Coded Aperture","type":"proj"},{"authors":["[Meng Li](https://bianlab.github.io/members.html)","[Liheng Bian](https://bianlab.github.io/)✉","[Guoan Zheng](https://smartimaging.uconn.edu/)","[Andrew Maiden](https://www.sheffield.ac.uk/eee/people/academic-staff/andrew-maiden)","[__Yang Liu__](https://yangliu.mit.edu/)","[Yiming Li](https://bianlab.github.io/members.html)","[Jinli Suo](https://sites.google.com/site/suojinli)","[Qionghai Dai](http://media.au.tsinghua.edu.cn)","Jun Zhang"],"categories":null,"content":"bibtex @article{Li21SPY, author = {Li, Meng and Bian, Liheng and Zheng, Guoan and Maiden, Andrew and Liu, Yang and Li, Yiming and Suo, Jinli and Dai, Qionghai and Zhang, Jun}, title = {Single-pixel ptychography}, journal = {Optics Letters}, doi = {10.1364/OL.417039}, year = {2021}, month = {4}, volume = {46}, number = {7}, pages = {1624--1627}, url = {https://doi.org/10.1364/OL.417039}, publisher = {Optica Publishing Group}, type = {Journal Article} } ","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"00094379261d007006c55a8d2c525292","permalink":"/proj/spi_ptychography/","publishdate":"2021-04-01T00:00:00Z","relpermalink":"/proj/spi_ptychography/","section":"proj","summary":"Ptychography is a predominant non-interferometric technique to image large complex fields but with quite a narrow working spectrum, because diffraction measurements require dense array detection with an ultra-high dynamic range. Here we report a single-pixel ptychography technique that realizes non-interferometric and non-scanning complex-field imaging in a wide waveband, where 2D dense detector arrays are not available. A single-pixel detector is placed in the far field to record the DC-only component of the diffracted wavefront scattered from the target field, which is illuminated by a sequence of binary modulation patterns. This decreases the measurements’ dynamic range by several orders of magnitude. We employ an efficient single-pixel phase-retrieval algorithm to jointly recover the field’s 2D amplitude and phase maps from the 1D intensity-only measurement sequence. No a priori object information is needed in the recovery process. We validate the technique’s quantitative phase imaging nature using both calibrated phase objects and biological samples and demonstrate its wide working spectrum with both 488-nm visible light and 980-nm near-infrared light.","tags":null,"title":"Single-Pixel Ptychography","type":"proj"},{"authors":["[Siming Zheng](https://github.com/zsm1211)†","[__Yang Liu__](https://yangliu.mit.edu/)†","[Ziyi Meng](https://scholar.google.com/citations?user=hfEq8gYAAAAJ)","[Mu Qiao](https://scholar.google.com/citations?user=-QMH8oAAAAAJ)","Zhishen Tong","Xiaoyu Yang","Shensheng Han","[Xin Yuan](https://scholar.google.com/citations?user=cS9CbWkAAAAJ)"],"categories":null,"content":"bibtex @article{Zheng20PnPCASSI, author = {Zheng, Siming and Liu, Yang and Meng, Ziyi and Qiao, Mu and Tong, Zhishen and Yang, Xiaoyu and Han, Shensheng and Yuan, Xin}, title = {Deep Plug-and-Play Priors for Spectral Snapshot Compressive Imaging}, journal = {Photonics Research}, doi = {10.1364/PRJ.411745}, volume = {9}, number = {2}, pages = {B18--B29}, year = {2021}, url = {https://doi.org/10.1364/PRJ.411745}, publisher = {Optical Society of America}, type = {Journal Article} } ","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611187200,"objectID":"3da13451be79892a5fa7a61c1691fae9","permalink":"/proj/sci_pnp_spectral/","publishdate":"2021-01-21T00:00:00Z","relpermalink":"/proj/sci_pnp_spectral/","section":"proj","summary":"We propose a plug-and-play (PnP) method, which uses deep-learning-based denoisers as regularization priors for spectral snapshot compressive imaging (SCI). Our method is efficient in terms of reconstruction quality and speed trade-off, and flexible to be ready-to-use for different compressive coding mechanisms. We demonstrate the efficiency and flexibility in both simulations and five different spectral SCI systems and show that the proposed deep PnP prior could achieve state-of-the-art results with a simple plug-in based on the optimization framework. This paves the way for capturing and recovering multi- or hyper-spectral information in one snapshot, which might inspire intriguing applications in remote sensing, biomedical science and material science.","tags":null,"title":"Deep Plug-and-Play Priors for Spectral Snapshot Compressive Imaging","type":"proj"},{"authors":["[Xin Yuan](https://scholar.google.com/citations?user=cS9CbWkAAAAJ)","[__Yang Liu__](https://yangliu.mit.edu/)","[Jinli Suo](https://sites.google.com/site/suojinli)","[Qionghai Dai](http://media.au.tsinghua.edu.cn)"],"categories":null,"content":"bibtex @inproceedings{Yuan20PnPSCI, author = {Yuan, Xin and Liu, Yang and Suo, Jinli and Dai, Qionghai}, title = {Plug-and-Play Algorithms for Large-scale Snapshot Compressive Imaging}, booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, doi = {10.1109/CVPR42600.2020.00152}, year = {2020}, month = {6}, pages = {1447 -- 1457}, arxiv = {2003.13654}, url = {https://doi.org/10.1109/CVPR42600.2020.00152}, publisher = {IEEE/CVF}, type = {Conference Proceedings} } ","date":1592006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592006400,"objectID":"4a592a0e208506c6dfd0a7237f2e8d8b","permalink":"/proj/sci_pnp/","publishdate":"2020-06-13T00:00:00Z","relpermalink":"/proj/sci_pnp/","section":"proj","summary":"Snapshot compressive imaging (SCI) aims to capture the high-dimensional (usually 3D) images using a 2D sensor (detector) in a single snapshot. Though enjoying the advantages of low-bandwidth, low-power and low-cost, applying SCI to large-scale problems (HD or UHD videos) in our daily life is still challenging. The bottleneck lies in the reconstruction algorithms; they are either too slow (iterative optimization algorithms) or not flexible to the encoding process (deep learning based end-to-end networks). In this paper, we develop fast and flexible algorithms for SCI based on the plug-and-play (PnP) framework. In addition to the widely used PnP-ADMM method, we further propose the PnP-GAP (generalized alternating projection) algorithm with a lower computational workload and prove the *global convergence* of PnP-GAP under the SCI hardware constraints. By employing deep denoising priors, we first time show that PnP can recover a UHD color video ($3840\\times 1644\\times 48$ with PNSR above 30dB) from a snapshot 2D measurement. Extensive results on both simulation and real datasets verify the superiority of our proposed algorithm.","tags":null,"title":"Plug-and-Play Algorithms for Large-Scale Snapshot Compressive Imaging","type":"proj"},{"authors":["[__Yang Liu__](https://yangliu.mit.edu/)†","[Xin Yuan](https://scholar.google.com/citations?user=cS9CbWkAAAAJ)†","[Jinli Suo](https://sites.google.com/site/suojinli)","[David J. Brady](https://www.optics.arizona.edu/person/david-brady)","[Qionghai Dai](http://media.au.tsinghua.edu.cn)✉"],"categories":null,"content":"bibtex @article{Liu19DeSCI, author = {Liu, Yang and Yuan, Xin and Suo, Jinli and Brady, David J. and Dai, Qionghai}, title = {Rank Minimization for Snapshot Compressive Imaging}, journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence}, doi = {10.1109/TPAMI.2018.2873587}, year = {2019}, month = {12}, volume = {41}, number = {12}, pages = {2990 -- 3006}, url = {https://doi.org/10.1109/TPAMI.2018.2873587}, publisher = {IEEE}, type = {Journal Article} } ","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"ac879cc2b3c58c6442400d1a6d2a4686","permalink":"/proj/sci_rank_minimization/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/proj/sci_rank_minimization/","section":"proj","summary":"Snapshot compressive imaging (SCI) refers to compressive imaging systems where multiple frames are mapped into a single measurement, with video compressive imaging and hyperspectral compressive imaging as two representative applications. Though exciting results of high-speed videos and hyperspectral images have been demonstrated, the poor reconstruction quality precludes SCI from wide applications.This paper aims to boost the reconstruction quality of SCI via exploiting the high-dimensional structure in the desired signal. We build a joint model to integrate the nonlocal self-similarity of video/hyperspectral frames and the rank minimization approach with the SCI sensing process. Following this, an alternating minimization algorithm is developed to solve this non-convex problem. We further investigate the special structure of the sampling process in SCI to tackle the computational workload and memory issues in SCI reconstruction. Both simulation and real data (captured by four different SCI cameras) results demonstrate that our proposed algorithm leads to significant improvements compared with current state-of-the-art algorithms. We hope our results will encourage the researchers and engineers to pursue further in compressive imaging for real applications.","tags":null,"title":"Rank Minimization for Snapshot Compressive Imaging","type":"proj"},{"authors":["Xukang Wang","[__Yang Liu__](https://yangliu.mit.edu/)","[Xiaofei Han](https://xiaofeitsinghua.github.io/)","[Jinli Suo](https://sites.google.com/site/suojinli)","[Qionghai Dai](http://media.au.tsinghua.edu.cn)"],"categories":null,"content":"bibtex @inproceedings{Wang19Snapshot, author = {Wang, Xukang and Liu, Yang and Han, Xiaofei and Suo, Jinli and Dai, Qionghai}, title = {Snapshot Compressive Volumetric Light-sheet Microscopy}, booktitle = {OSA Biophotonics Congress}, volume = {Bio-Optics: Design and Application (BODA)}, pages = {JW5A.5}, year = {2019}, organization = {Optical Society of America} } ","date":1555200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555200000,"objectID":"eb46cc2a3b18f968643c081128ea8b4b","permalink":"/proj/sci_light-sheet/","publishdate":"2019-04-14T00:00:00Z","relpermalink":"/proj/sci_light-sheet/","section":"proj","summary":"We proposed a snapshot compressive volumetric light-sheet microscopy method for high-speed three-dimensional imaging of zebrafish and cleared mouse brain.","tags":null,"title":"Snapshot Compressive Volumetric Light-sheet Microscopy","type":"proj"},{"authors":["[__Yang Liu__](https://yangliu.mit.edu/)","[Jinli Suo](https://sites.google.com/site/suojinli)","[Yuanlong Zhang](http://media.au.tsinghua.edu.cn/Yuanlong%20Zhang/YuanlongZhang.jsp)","[Qionghai Dai](http://media.au.tsinghua.edu.cn)"],"categories":null,"content":"bibtex @article{Liu18Singlepixel, author = {Liu, Yang and Suo, Jinli and Zhang, Yuanlong and Dai, Qionghai}, title = {Single-pixel phase and fluorescence microscope}, journal = {Optics Express}, doi = {10.1364/OE.26.032451}, year = {2018}, month = {12}, volume = {26}, number = {25}, pages = {32451 -- 32462}, url = {https://doi.org/10.1364/OE.26.032451}, publisher = {Optical Society of America}, type = {Journal Article} } ","date":1544400000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544400000,"objectID":"d0b98bae27ce7d7e60ccbf99b9c9156d","permalink":"/proj/spi_qfm/","publishdate":"2018-12-10T00:00:00Z","relpermalink":"/proj/spi_qfm/","section":"proj","summary":"Multimodal microscopes either use multiple cameras or a single camera to multiplex different modes spatially. The former needs expertise demanding alignment and the latter suffers from limited spatial resolution. Here, we report an alignment-free full-resolution simultaneous fluorescence and phase imaging approach using single-pixel detectors. By combining reference-free interferometry with single-pixel imaging scheme, we employ structured illumination to encode the phase and fluorescence of the sample into two single-pixel detection arms, and then conduct reconstruction computationally from the illumination patterns and recorded correlated measurements. The recovered fluorescence and phase images are inherently aligned thanks to single-pixel imaging scheme. To validate the proposed method, we built a proof-of-concept setup for first imaging the phase of an etched glass with given etching depth and then imaging the phase and fluorescence of the quantum dot sample. This method holds great potential for multispectral fluorescence microscopy with additional single-pixel detectors or a spectrometer. Besides, this cost-efficient multimodal system might find broad applications in biomedical science and material science.","tags":null,"title":"Single-pixel phase and fluorescence microscope","type":"proj"},{"authors":["[__Yang Liu__](https://yangliu.mit.edu/)","[Jinli Suo](https://sites.google.com/site/suojinli)","[Yuanlong Zhang](http://media.au.tsinghua.edu.cn/Yuanlong%20Zhang/YuanlongZhang.jsp)","[Qionghai Dai](http://media.au.tsinghua.edu.cn)"],"categories":null,"content":"bibtex @inproceedings{Liu18Simultaneous, author = {Liu, Yang and Suo, Jinli and Zhang, Yuanlong and Dai, Qionghai}, title = {Simultaneous fluorescence and quantitative phase microscopy with single-pixel detectors}, booktitle = {Proc. SPIE, Quantitative Phase Imaging IV}, volume = {10503}, pages = {105032K}, year = {2018}, organization = {International Society for Optics and Photonics} } ","date":1517184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517184000,"objectID":"3c919048fb02e068e871ef0040475448","permalink":"/proj/spi_fluo_qpi/","publishdate":"2018-01-29T00:00:00Z","relpermalink":"/proj/spi_fluo_qpi/","section":"proj","summary":"Multimodal microscopy offers high flexibilities for biomedical observation and diagnosis. Conventional multimodal approaches either use multiple cameras or a single camera spatially multiplexing different modes. The former needs expertise demanding alignment and the latter suffers from limited spatial resolution. Here, we report an alignment-free full-resolution simultaneous fluorescence and quantitative phase imaging approach using single-pixel detectors. By combining reference-free interferometry with single-pixel detection, we encode the phase and fluorescence of the sample in two detection arms at the same time. Then we employ structured illumination and the correlated measurements between the sample and the illuminations for reconstruction. The recovered fluorescence and phase images are inherently aligned thanks to single-pixel detection. To validate the proposed method, we built a proof-of-concept setup for first imaging the phase of etched glass with the depth of a few hundred nanometers and then imaging the fluorescence and phase of the quantum dot drop. This method holds great potential for multispectral fluorescence microscopy with additional single-pixel detectors or a spectrometer. Besides, this cost-efficient multimodal system might find broad applications in biomedical science and neuroscience.","tags":null,"title":"Simultaneous fluorescence and quantitative phase microscopy with single-pixel detectors","type":"proj"},{"authors":["[Yuwang Wang](https://www.researchgate.net/profile/Yuwang_Wang)","[__Yang Liu__](https://yangliu.mit.edu/)","[Jinli Suo](https://sites.google.com/site/suojinli)","[Guohai Situ](http://www.escience.cn/people/situ/)","Chang Qiao","[Qionghai Dai](http://media.au.tsinghua.edu.cn)"],"categories":null,"content":"bibtex @article{Wang17Highspeed, author = {Wang, Yuwang and Liu, Yang and Suo, Jinli and Situ, Guohai and Qiao, Chang and Dai, Qionghai}, title = {High Speed Computational Ghost Imaging via Spatial Sweeping}, journal = {Scientific Reports}, doi = {10.1038/srep45325}, year = {2017}, month = {3}, volume = {7}, pages = {45325}, url = {https://doi.org/10.1038/srep45325}, publisher = {Nature Publishing Group}, type = {Journal Article} } ","date":1490832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490832000,"objectID":"c8f9569aaf7ea5f30e3979b32bc0b732","permalink":"/proj/spi_high_speed/","publishdate":"2017-03-30T00:00:00Z","relpermalink":"/proj/spi_high_speed/","section":"proj","summary":"Computational ghost imaging (CGI) achieves single-pixel imaging by using a Spatial Light Modulator (SLM) to generate structured illuminations for spatially resolved information encoding. The imaging speed of CGI is limited by the modulation frequency of available SLMs, and sets back its practical applications. This paper proposes to bypass this limitation by trading off SLM’s redundant spatial resolution for multiplication of the modulation frequency. Specifically, a pair of galvanic mirrors sweeping across the high resolution SLM multiply the modulation frequency within the spatial resolution gap between SLM and the final reconstruction. A proof-of-principle setup with two middle end galvanic mirrors achieves ghost imaging as fast as **42 Hz** at 80 × 80-pixel resolution, **5** times faster than state-of-the-arts, and holds potential for one magnitude further multiplication by hardware upgrading. Our approach brings a significant improvement in the imaging speed of ghost imaging and pushes ghost imaging towards practical applications.","tags":null,"title":"High-speed computational ghost imaging via spatial sweeping","type":"proj"}]